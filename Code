import os
dataset_path=r'D:\Hemavathy\Engineering\3rdyear\6thSem\Project\AIML\dataset1'
os.listdir(dataset_path)
import tensorflow as tf
data_dir=r'D:\Hemavathy\Engineering\3rd year\6th Sem\Project\AIML\dataset1'
# Create dataset, resize to 1024x1024
dataset = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    labels=None,                 
    image_size=(1024, 1024),     
    batch_size=8,                # Smaller batch size because images are bigger
    shuffle=True
)
# Normalize pixel values
normalization_layer = tf.keras.layers.Rescaling(1./255)
dataset = dataset.map(lambda x: normalization_layer(x))
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras.preprocessing import image
def load_custom_dataset_with_noisy(data_dir, size=(1024, 1024), grayscale=True, limit=None, low_res_size=(256, 256)):
    clean_images = []
    noisy_images = []
    # Get paths to all clean images
    clean_paths = sorted([os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if fname.endswith(('.jpg', '.png'))])
    for i, clean_path in enumerate(clean_paths):
        # Load clean image
        clean_img = image.load_img(clean_path, target_size=size)
        clean_img = image.img_to_array(clean_img)
        # Resize clean image to match target size
        clean_img = tf.image.resize(clean_img, size)
        if grayscale:
            clean_img = tf.image.rgb_to_grayscale(clean_img)
        clean_img = tf.cast(clean_img, tf.float32) / 255.0
        clean_images.append(clean_img.numpy())
        # Create noisy image by adding salt-and-pepper noise
        noisy_img = add_salt_and_pepper_noise(clean_img.numpy(), noise_prob=0.05)  # 5% noise
        noisy_images.append(noisy_img)
        if limit and i + 1 >= limit:
            break
    # Convert lists to NumPy arrays
    clean_images = np.array(clean_images)
    noisy_images = np.array(noisy_images)
    return noisy_images, clean_images
def add_salt_and_pepper_noise(image, noise_prob=0.05):
    # Add salt-and-pepper noise to the image
    noisy_img = image.copy()
    total_pixels = noisy_img.size
    num_salt = int(total_pixels * noise_prob / 2)
    num_pepper = int(total_pixels * noise_prob / 2)
    # Salt noise
    salt_coords = np.random.randint(0, noisy_img.shape[0], num_salt), np.random.randint(0, noisy_img.shape[1], num_salt)
    noisy_img[salt_coords] = 1  # White pixels
    # Pepper noise
    pepper_coords = np.random.randint(0, noisy_img.shape[0], num_pepper), np.random.randint(0, noisy_img.shape[1], num_pepper)
    noisy_img[pepper_coords] = 0  # Black pixels

    return noisy_img
noisy_images, clean_images = load_custom_dataset_with_noisy(
    data_dir,  # Your dataset folder
    size=(1024, 1024),        # Size of the high-resolution clean image
    grayscale=True,           # Convert to grayscale
    limit=200,                # Load only 200 images
    low_res_size=(256, 256)   # Size for the simulated noisy image (low resolution)
)
print("Noisy images shape:", noisy_images.shape)
print("Clean images shape:", clean_images.shape)
from sklearn.model_selection import train_test_split
# Split the noisy and clean images into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(noisy_images, clean_images, test_size=0.2, random_state=42)
# Print shapes of the splits
print(f"Training set: {x_train.shape}, Validation set: {x_val.shape}")
from tensorflow.keras import layers, models
def build_denoising_autoencoder(input_shape):
    # Encoder part
    input_img = layers.Input(shape=input_shape)
    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)
    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2), padding='same')(x)
    # Decoder part
    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)
    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.UpSampling2D((2, 2))(x)

    # Output layer
    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)  # 1 channel for grayscale
    # Build the model
    autoencoder = models.Model(input_img, decoded)
    autoencoder.compile(optimizer='adam', loss='mean_squared_error')
    return autoencoder
# Build the model
model = build_denoising_autoencoder(input_shape=(1024, 1024, 1))
# Display the model summary
model.summary()
# Train the model
history = model.fit(x_train, y_train, epochs=10, batch_size=2, validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
# Plot training & validation loss values
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy("mixed_float16")
import numpy as np
import tensorflow as tf
def compute_psnr_ssim_dataset(noisy_images, clean_images):
    psnr_values = []
    ssim_values = []
    for noisy, clean in zip(noisy_images, clean_images):
        # Ensure images are float32 and [0, 1]
        noisy = tf.convert_to_tensor(noisy, dtype=tf.float32)
        clean = tf.convert_to_tensor(clean, dtype=tf.float32)
        psnr = tf.image.psnr(noisy, clean, max_val=1.0)
        ssim = tf.image.ssim(noisy, clean, max_val=1.0)
        psnr_values.append(psnr.numpy())
        ssim_values.append(ssim.numpy())
    avg_psnr = np.mean(psnr_values)
    avg_ssim = np.mean(ssim_values)
    return avg_psnr, avg_ssim
# Example usage:
avg_psnr, avg_ssim = compute_psnr_ssim_dataset(noisy_images, clean_images)
print(f"Average PSNR: {avg_psnr:.2f} dB")
print(f"Average SSIM: {avg_ssim:.4f}")
import tensorflow as tf
import numpy as np
# Step 1: Load and preprocess the image
img_path = r'D:\Hemavathy\Engineering\3rd year\6th Sem\Project\AIML\noised image\noisy_image.jpg'
# Read the image file into a binary tensor
img_data = tf.io.read_file(impeach)
# Decode it into a tensor (grayscale: channels=1)
img = tf.image.decode_image(img_data, channels=1)
# Resize to model's expected size
img = tf.image.resize(img, [1024, 1024])  
# Normalize pixel values to [0, 1]
img = img / 255.0
# Expand dimensions to simulate batch (model expects batch dimension)
img = tf.expand_dims(img, axis=0)  # Shape: (1, 1024, 1024, 1)

# Step 2: Predict
denoised_image = model.predict(img)
# Remove batch dimension if needed
denoised_image = np.squeeze(denoised_image)
# Fine-tune the model (continue training)
history_finetune = model.fit(x_train, y_train, epochs=10, batch_size=4, validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
# Plot training & validation loss values
plt.figure(figsize=(8,5))
plt.plot(history_finetune.history['loss'], label='Train Loss')
plt.plot(history_finetune.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()
import matplotlib.pyplot as plt
# Predict denoised images from the validation set
denoised_images = model.predict(x_val)
# Visualize the first image in the validation set
index = 0
plt.figure(figsize=(12, 4))
# Noisy image
plt.subplot(1, 3, 1)
plt.imshow(x_val[index].reshape(1024, 1024), cmap='gray')
plt.title("Noisy Image")
plt.axis('off')

# Clean image (ground truth)
plt.subplot(1, 3, 2)
plt.imshow(y_val[index].reshape(1024, 1024), cmap='gray')
plt.title("Clean Image")
plt.axis('off')
# Denoised image (prediction)
plt.subplot(1, 3, 3)
plt.imshow(denoised_images[index].reshape(1024, 1024), cmap='gray')
plt.title("Denoised Image")
plt.axis('off')
plt.show()
import cv2
import numpy as np
def enhance_contrast(img):
    img = img.squeeze()  # remove extra dimensions
    img = (img * 255).astype('uint8')  # convert to 8-bit
    equalized = cv2.equalizeHist(img)
    return equalized
denoised_img = denoised_images[index]  # assuming it's shape (1, 512, 512, 1)
enhanced_img = enhance_contrast(denoised_img)
plt.imshow(enhanced_img,cmap='gray')
def sharpen_image(img):
    img = img.squeeze()
    img = (img * 255).astype('uint8')
    kernel = np.array([[0, -1, 0],
                       [-1, 5,-1],
                       [0, -1, 0]])
    sharpened = cv2.filter2D(img, -1, kernel)
    return sharpened
def adjust_gamma(img, gamma=1.2):
    img = img.squeeze()
    img = np.clip(img, 0, 1)
    img = np.power(img, gamma)
    return img
img = denoised_images[index]
img = enhance_contrast(img)
img = sharpen_image(img)
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.imshow(denoised_images[index].squeeze(), cmap='gray')
plt.title("Denoised Image")
plt.axis('off')
plt.subplot(1, 3, 2)
plt.imshow(enhanced_img, cmap='gray')
plt.title("Enhanced Image")
plt.axis('off')
plt.tight_layout()
plt.show()
import cv2
def unsharp_mask(img):
    img = (img * 255).astype('uint8') if img.max() <= 1 else img
    blurred = cv2.GaussianBlur(img, (9, 9), 10.0)
    sharpened = cv2.addWeighted(img, 1.5, blurred, -0.5, 0)
    return sharpened
def clahe_contrast(img):
    img = (img * 255).astype('uint8') if img.max() <= 1 else img
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(img)
img = denoised_images[index].squeeze()  # Shape: (512, 512)
# Step 1: CLAHE
img = clahe_contrast(img)

# Step 2: Unsharp Masking
img = unsharp_mask(img)
# Step 3: Normalize for display
img = np.clip(img, 0, 255).astype('uint8')
# Show it
plt.imshow(img, cmap='gray')
plt.title("High Clarity Enhanced Image")
plt.axis('off')
plt.show()
import cv2
import numpy as np
def clahe_contrast(img):
    img = (img * 255).astype('uint8') if img.max() <= 1 else img
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    return clahe.apply(img)
def unsharp_mask(img):
    img = (img * 255).astype('uint8') if img.max() <= 1 else img
    blurred = cv2.GaussianBlur(img, (9, 9), 10.0)
    sharpened = cv2.addWeighted(img, 1.5, blurred, -0.5, 0)
    return sharpened
# Denoised image from your model
denoised = denoised_images[index].squeeze()  # shape: (512, 512)
# Apply contrast and sharpening
enhanced = clahe_contrast(denoised)
enhanced = unsharp_mask(enhanced)
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.imshow(denoised, cmap='gray')
plt.title("Denoised")
plt.axis('off')
plt.subplot(1, 3, 2)
plt.imshow(enhanced, cmap='gray')
plt.title("Enhanced")
plt.axis('off')
plt.subplot(1, 3, 3)
plt.hist(enhanced.ravel(), bins=256, range=(0, 256))
plt.title("Histogram")
plt.tight_layout()
plt.show()
import numpy as np
import matplotlib.pyplot as plt
# Assuming 'enhanced' is a NumPy array (grayscale image) with values from 0 to 1 or 0 to 255
# If it's in range 0-1, convert to 0-255 for better colormap contrast
if np.max(enhanced_img) <= 1.0:
    heatmap_data = (enhanced_img * 255).astype(np.uint8)
else:
    heatmap_data = enhanced_img.astype(np.uint8)
# Plotting the heatmap
plt.figure(figsize=(8, 8))
plt.imshow(heatmap_data, cmap='magma')
plt.colorbar(label='Pixel Intensity')
plt.title('Heatmap of Enhanced Image')
plt.axis('off')
plt.show()
import numpy as np
import matplotlib.pyplot as plt
# Assuming 'enhanced' is a NumPy array (grayscale image) with values from 0 to 1 or 0 to 255
# If it's in range 0-1, convert to 0-255 for better colormap contrast
if np.max(enhanced) <= 1.0:
    heatmap_data = (enhanced * 255).astype(np.uint8)
else:
    heatmap_data = enhanced.astype(np.uint8)
# Plotting the heatmap
plt.figure(figsize=(8, 8))
plt.imshow(heatmap_data, cmap='magma') 
plt.colorbar(label='Pixel Intensity')
plt.title('Heatmap of Enhanced sharpened Image')
plt.axis('off')
plt.show()
from PIL import Image
import numpy as np
# Assuming 'enhanced_img' is a numpy array
# First, convert it to uint8, if it's in the float32 or float64 format
enhanced_img_uint8 = np.clip(enhanced, 0, 255).astype(np.uint8)
# Now convert it to a PIL image and save it
enhanced_pil = Image.fromarray(enhanced_img_uint8)
enhanced_pil.save(r"D:\Hemavathy\Engineering\3rd year\6th Sem\Project\AIML\black-and-white_sharpened\enhanced_image_rgb.jpg")
# Verify by opening and showing it
enhanced_pil.show()
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
# Load the saved image
img = Image.open("enhanced_image_rgb.jpg")
# Convert to numpy and check pixel values
img_np = np.array(img)
# Show stats
print("Image shape:", img_np.shape)
print("Min pixel value:", img_np.min())
print("Max pixel value:", img_np.max())
print("Mean pixel value:", img_np.mean())
# Show image
plt.imshow(img_np)
plt.title("Saved Enhanced Image")
plt.axis('off')
plt.show()
import cv2
import numpy as np
import matplotlib.pyplot as plt
# Load the grayscale medical image
gray_image = cv2.imread(r'D:\Hemavathy\Engineering\3rd year\6th Sem\Project\AIML\black-and-white_sharpened\enhanced_image_rgb.jpg', cv2.IMREAD_GRAYSCALE)
# Apply gamma correction
gamma = 1.5  # Adjust gamma for different effects
gamma_corrected_image = np.array(255 * (gray_image / 255) ** gamma, dtype='uint8')
# Apply a colormap to the gamma-corrected image
colorized_image = cv2.applyColorMap(gamma_corrected_image, cv2.COLORMAP_HOT)
# Display the original and colorized images
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title('Original Grayscale')
plt.axis('off')
plt.subplot(1, 2, 2)
plt.imshow(colorized_image)
plt.title('Gamma-Corrected Colorized Image')
plt.axis('off')
plt.show()

# Optionally save the colorized image
cv2.imwrite(r'D:\Hemavathy\Engineering\3rd year\6th Sem\Project\AIML\colour_images\colourized_img.jpg', colorized_image)
import cv2
import numpy as np
import matplotlib.pyplot as plt
# Load the colorized image (you can use the colorized image from previous steps)
colorized_image = cv2.imread(r'D:\Hemavathy\Engineering\3rd year\6th Sem\Project\AIML\colour_images\colourized_img.jpg')
# --- Sharpening ---
# Create a kernel for sharpening
sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
# Apply the kernel to the image using cv2.filter2D
sharpened_image = cv2.filter2D(colorized_image, -1, sharpen_kernel)
# --- Contrast Enhancement using CLAHE ---
# Convert the image to LAB color space for better contrast enhancement
lab_image = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2LAB)
# Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) on the L channel (luminance)
l, a, b = cv2.split(lab_image)
clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
l = clahe.apply(l)
# Merge the channels back
enhanced_lab_image = cv2.merge((l, a, b))
# Convert back to BGR color space
contrast_enhanced_image = cv2.cvtColor(enhanced_lab_image, cv2.COLOR_LAB2BGR)
# --- Denoising using Bilateral Filter ---
# Apply bilateral filter to smooth the image while preserving edges
denoised_image = cv2.bilateralFilter(contrast_enhanced_image, d=9, sigmaColor=75, sigmaSpace=75)

# --- Display Results ---
# Display the original and processed images
plt.figure(figsize=(12, 12))
plt.subplot(2, 2, 1)
plt.imshow(cv2.cvtColor(colorized_image, cv2.COLOR_BGR2RGB))
plt.title('Original Colorized Image')
plt.axis('off')
plt.subplot(2, 2, 2)
plt.imshow(cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2RGB))
plt.title('Sharpened Image')
plt.axis('off')
plt.subplot(2, 2, 3)
plt.imshow(cv2.cvtColor(contrast_enhanced_image, cv2.COLOR_BGR2RGB))
plt.title('Contrast Enhanced Image (CLAHE)')
plt.axis('off')
plt.subplot(2, 2, 4)
plt.imshow(cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB))
plt.title('Denoised Image (Bilateral Filter)')
plt.axis('off')
plt.show()
# Optionally save the final enhanced image
cv2.imwrite('final_enhanced_image.jpg', denoised_image)
